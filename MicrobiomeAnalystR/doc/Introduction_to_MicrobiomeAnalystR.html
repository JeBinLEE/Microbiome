<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="Jasmine Chong, Peng Liu and Jeff Xia" />

<meta name="date" content="2025-10-01" />

<title>Introduction to MicrobiomeAnalystR</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>
<script>// Hide empty <a> tag within highlighted CodeBlock for screen reader accessibility (see https://github.com/jgm/pandoc/issues/6352#issuecomment-626106786) -->
// v0.0.1
// Written by JooYoung Seo (jooyoung@psu.edu) and Atsushi Yasumoto on June 1st, 2020.

document.addEventListener('DOMContentLoaded', function() {
  const codeList = document.getElementsByClassName("sourceCode");
  for (var i = 0; i < codeList.length; i++) {
    var linkList = codeList[i].getElementsByTagName('a');
    for (var j = 0; j < linkList.length; j++) {
      if (linkList[j].innerHTML === "") {
        linkList[j].setAttribute('aria-hidden', 'true');
      }
    }
  }
});
</script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>



<style type="text/css">
  code {
    white-space: pre;
  }
  .sourceCode {
    overflow: visible;
  }
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Introduction to MicrobiomeAnalystR</h1>
<h4 class="author">Jasmine Chong, Peng Liu and Jeff Xia</h4>
<h4 class="date">2025-10-01</h4>



<div id="overview-of-microbiomeanalystr" class="section level2">
<h2>1.0 Overview of MicrobiomeAnalystR</h2>
<p>MicrobiomeAnalystR is a R package, synchronized with the popular MicrobiomeAnalyst web server, designed for comprehensive microbiome data analysis, visualization, and interpretation. This R package contains the numerous R functions and libraries underlying the web server necessary to perform microbiome data processing and analysis. This package provides support either amplicon sequencing data - Operational Taxonomic Units (OTU) or Amplicon Sequencing Variants data (ASV), as well as shotgun metagenomics/meta-transcriptomic gene abundance data. Particularly, it supports .txt, .csv, .biom, and .shared file formats.</p>
<p>MicrobiomeAnalystR is comprised of four modules: (i) Marker Data Profiling (MDP) which is dedicated to the analysis of 16S rRNA marker gene survey data, (ii) Shotgun Data Profiling (SDP) for the analysis of metagenomics or metatranscriptomics data, (iii) Projection to Public Data (PPD) for users to visually compare their marker gene data with public datasets available within MicrobiomeAnalyst, and (iv) Taxon Set Enrichment Analysis (TSEA) to identify whether predefined groups of taxa are statistically overrepresented in a list of taxa. All four modules implement the same general workflow - data preparation, followed by data analysis and visual exploration. In the data preparation stage, user’s data is uploaded for filtering and normalization. Following this, a wide variety of statistical and visualization methods can be performed on the processed data to detect overall patterns, significant features, functional insights, etc.</p>
<p>Following installation and loading of MicrobiomeAnalystR, users will be able to reproduce web server results from their local computers using the corresponding R command history downloaded from MicrobiomeAnalyst, thereby achieving maximum flexibility and reproducibility. MicrobiomeAnalystR serves as a platform to enable users to perform high-quality, comprehensive microbiome data analysis, as well as produce computationally and statistically reproducible analytical workflows. The aim of this vignette is to provide an overview of how to use MicrobiomeAnalystR to perform comprehensive microbiome data analysis and visualization. In detail, this vignette will go through the steps of data import, processing, normalization, and filtering.</p>
</div>
<div id="loading-the-package" class="section level2">
<h2>1.1 Loading the package</h2>
<p>After following the installation instructions on the MicrobiomeAnalystR Github, you will be ready to use the package. Use the library() function to load the package into R.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true"></a><span class="co"># Load MicrobiomeAnalystR</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true"></a><span class="kw">library</span>(MicrobiomeAnalystR)</span></code></pre></div>
</div>
<div id="tips-for-using-the-microbiomeanalystr-package" class="section level2">
<h2>1.2 Tips for using the MicrobiomeAnalystR package</h2>
<ol style="list-style-type: decimal">
<li><p>The first function that you will use in every module is the <em>Init.mbSetObj</em> function, which constructs the mbSetObj object that stores user’s data for further processing and analysis. On the MicrobiomeAnalyst web-server, the suggested name of the mbSetObj, which must be called consistently in your workflow, is <em>mbSet</em>. It is not necessary to use this format. Users can use any name they prefer, as long as it is called exactly the same in each step. Note that the object must be called <em>mbSet</em> to generate the Analysis Report.</p></li>
<li><p>The MicrobiomeAnalystR package directly creates data files/plots/tables/analysis outputs in your current working directory. It is not necessary to call any plotting functions onto the created mbSetObj.</p></li>
<li><p>Every command must be run in sequence, please do not skip any commands as this will result in errors downstream.</p></li>
<li><p>Each main function in MicrobiomeAnalyst is documented. Use the ?Function format to open its documentation. For instance, use ?MicrobiomeAnalystR::CreatePhyloseqObj to find out more about this function.</p></li>
</ol>
</div>
<div id="data-format" class="section level2">
<h2>1.3 Data Format</h2>
<p>MicrobiomeAnalystR supports the upload of abundance data from several commonly used bioinformatic pipelines including DADA2, QIIME, mothur, BIOM, and UPARSE. These files can be uploaded in a simple text format (.txt or .csv format), or directly as .biom or .shared files. Users must also provide a metadata file containing group information fort the same sample IDs. The following are short descriptors of how to format the abundance, taxonomy, and metadata files for MicrobiomeAnalystR. Note that the sample and feature names must match across all uploaded files.</p>
<div id="abundance-files-.txt.csv" class="section level3">
<h3>Abundance files (.txt/.csv)</h3>
<p>The abundance table should be formatted so that features are rows and samples are columns. The first line should start with “#NAME”. If the feature names contain taxon names, ensure that the taxa levels are separated by semicolons (e.g. Bacteria; Firmicutes; Clostridia;). If the features do not contain specific taxon names (e.g. OTU000001), a taxonomy mapping file must also be provided (see below).</p>
</div>
<div id="taxonomy-files-.txt.csv" class="section level3">
<h3>Taxonomy files (.txt/.csv)</h3>
<p>The taxonomy file should be formatted so that feature names are in the first column, beginning with “#TAXONOMY”. Each row should then contain the taxonomic classification of all the features under the column subheadings “Phylum”, “Class”, “Order”, “Family”, “Genus”, and “Species”.</p>
</div>
<div id="metadata-files-.txt.csv" class="section level3">
<h3>Metadata files (.txt/.csv)</h3>
<p>The metadata file should be formatted so that the first column contains the sample names, starting with “#NAME”. Subsequent columns should contain the variables of interest</p>
</div>
</div>
<div id="reading-in-data-files" class="section level2">
<h2>1.4 Reading in Data Files</h2>
<p>The first step of any analysis is to read in the data. After initiating the mbSetObj, users will use the <em>SetAnalType</em> to specify that which workflow they would like to perform. If their data is marker gene data, use “markergene”, if their data is shotgun metagenomics or transcriptomics data, use &quot;“shotgun”. If they will be performing the Projection with Public Data module, use “dataprojection”. If they will be performing Taxon Set Enrichment Analysis, use “species”. Next, use the <em>Read16SAbundData</em> function to read in the abundance file. Dependent on the data format, users will need to specify if their file is .txt (“text”), .biom (“biom”), or .shared (“mothur”). If the taxonomy lables are not included in the abundance file, use the <em>Read16STaxaTable</em> to read in the taxonomy table. Also, if metadata is not included in the abundance file, use the <em>ReadSampleTable</em> to read in the metadata file. Use the <em>ReadTreeFile</em> to read in your phylogenetic tree (optional). After uploading files, a data integrity check must be performed to verify that the data are suitable for downstream analysis using the <em>SanityCheckData</em> function. For instance, it will check that the sample names match (abundance table vs. metadata), that feature reads exist in more than 2 samples, and removes features with 0 variance.</p>
<p>MicrobiomeAnalystR provides multiple example datasets for testing purposes available from the Tutorials page of the MicrobiomeAnalyst web-server (<a href="https://www.microbiomeanalyst.ca/MicrobiomeAnalyst/faces/docs/Resources.xhtml" class="uri">https://www.microbiomeanalyst.ca/MicrobiomeAnalyst/faces/docs/Resources.xhtml</a>). For this tutorial, we will use the IBD dataset which consists of 43 stool samples from pediatric Inflammatory Bowel Disease (IBD) patients and healthy controls from the Integrated Human Microbiome Project (iHMP) (<a href="https://www.hmpdacc.org/ihmp/" class="uri">https://www.hmpdacc.org/ihmp/</a>). This data was preprocessed using the DADA2 pipeline integrated within the MicrobiomeAnalystR package. After the data integrity check, use the <em>CreatePhyloseqObj</em> function to create a phyloseq object from the mbSetObj. phyloseq (3) is the microbiome data analysis workhorse of the R environment, and MicrobiomeAnalystR is built upon this R package. The proc.phyobj contains the OTU table, taxonomy table, and metadata. The object can be found in the mbSetObj and is used downstream in many functions.</p>
<p>The set of functions below shows how to upload the example IBD data.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true"></a><span class="co"># Initiate the mbSetObj</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true"></a>mbSet&lt;-<span class="kw">Init.mbSetObj</span>()</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true"></a><span class="co"># Set the analysis type</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true"></a>mbSet&lt;-<span class="kw">SetModuleType</span>(mbSet, <span class="st">&quot;mdp&quot;</span>)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true"></a><span class="co"># Read in the abundance file, file format is .txt, taxa labels not included in the abundance file,</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true"></a><span class="co"># taxonomy labels are Greengenes, metadata file is included separately, and the selected module is 16S.</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true"></a>mbSet&lt;-<span class="kw">Read16SAbundData</span>(mbSet, <span class="dt">dataName=</span><span class="st">&quot;ibd_asv_table.txt&quot;</span>, <span class="dt">format=</span><span class="st">&quot;text&quot;</span>, <span class="dt">taxa_type=</span><span class="st">&quot;Greengenes&quot;</span>, <span class="dt">ismetafile=</span><span class="st">&quot;T&quot;</span>);</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true"></a></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true"></a><span class="co"># Read in the metadata file</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true"></a>mbSet&lt;-<span class="kw">ReadSampleTable</span>(mbSet, <span class="dt">dataName=</span><span class="st">&quot;ibd_meta.csv&quot;</span>);</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true"></a></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true"></a><span class="co"># Read in the taxonomy table</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true"></a>mbSet&lt;-<span class="kw">Read16STaxaTable</span>(mbSet, <span class="dt">dataName=</span><span class="st">&quot;ibd_taxa.txt&quot;</span>);</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true"></a></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true"></a><span class="co"># Read in the phylogenetic tree file</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true"></a>mbSet&lt;-<span class="kw">ReadTreeFile</span>(mbSet, <span class="dt">dataName=</span><span class="st">&quot;ibd_tree.tre&quot;</span>);</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true"></a></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true"></a><span class="co"># Data integrity check</span></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true"></a>mbSet&lt;-<span class="kw">SanityCheckData</span>(mbSet, <span class="dt">filetype=</span><span class="st">&quot;text&quot;</span>);</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true"></a></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true"></a><span class="co"># Create phyloseq object</span></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true"></a>mbSet&lt;-<span class="kw">CreatePhyloseqObj</span>(mbSet, <span class="dt">type=</span><span class="st">&quot;text&quot;</span>, <span class="dt">taxa_type=</span><span class="st">&quot;Greengenes&quot;</span>, <span class="dt">taxalabel=</span><span class="st">&quot;F&quot;</span>)</span></code></pre></div>
</div>
<div id="data-processing" class="section level2">
<h2>2.0 Data Processing</h2>
<p>Feature abundance data generated from amplicon sequencing or metagenomic data are affected by various sources of systematic variability (1). The abundance data are plagued by uneven sequence depths between samples. Moreover, systematic variability can arise from technical errors during sequencing. Normalization aims to remove or reduce such systematic variability. These methods can be classified as rarefying, scaling, and transforming. The merits and pitfalls of the most commonly used methods are further discussed below. Note that data normalization is certainly not one-size-fits-all (2). Rather, the choice of normalization method is dependent on the type of analyses to be performed.</p>
</div>
<div id="data-filtering" class="section level2">
<h2>2.1 Data Filtering</h2>
<p>The purpose of data filtering is to allow users to remove low quality and/or uninformative features to improve downstream statistical analysis. MicrobiomeAnalyst contains three data filtering procedures: Minimal data filtering (applied to all analysis) - the procedure will remove features containing all zeros or appearing in only one sample. These extremely rare features should be removed from consideration; Low abundance features (<em>ApplyAbundanceFilter</em>) - they may be due to sequencing errors or low-level contaminations; Low variance features (<em>ApplyVarianceFilter</em>) - they are unlikely to be associated with the conditions under study; Note, the last two options are not used for within-sample (alpha diversity) profiling but are strongly recommended for comparative analysis. To disable the filtering step, set the count in <em>ApplyAbundanceFilter</em> to 0 and in <em>ApplyVarianceFilter</em> the filtPerct to 0.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true"></a><span class="co"># Low abundance filtering, based on the prevalence of features. In this case, by </span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true"></a><span class="co"># setting the sample percentage to 0.2, only features with &gt;4 counts in at least 20% of all samples</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true"></a><span class="co"># will be retained.</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true"></a>mbSet&lt;-<span class="kw">ApplyAbundanceFilter</span>(mbSet, <span class="dt">filt.opt=</span><span class="st">&quot;prevalence&quot;</span>, <span class="dt">count=</span><span class="dv">4</span>, <span class="dt">smpl.perc=</span><span class="fl">0.2</span>);</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true"></a><span class="co"># Low variance filtering, based on the inter-quantile range. Here, variance is calculated using</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true"></a><span class="co"># IQR and 10% of the lowest variance features will be removed.</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true"></a>mbSet&lt;-<span class="kw">ApplyVarianceFilter</span>(mbSet, <span class="dt">filtopt=</span><span class="st">&quot;iqr&quot;</span>, <span class="dt">filtPerct=</span><span class="fl">0.1</span>);</span></code></pre></div>
</div>
<div id="data-normalization" class="section level2">
<h2>2.2 Data Normalization</h2>
<p>Users of MicrobiomeAnalystR can perform data rarefying, scaling, and transformation using the <em>PerformNormalization</em> function. The aim of data normalization is to standardize the data to enable accurate comparisons.</p>
<p><strong>Data rarefying</strong></p>
<p>Rarefying is commonly used to account for uneven library sizes. This method works by randomly subsampling read counts of samples without replacement to the lowest read depth of a sample. It has been admonished due to the potential of discarding of useful information. However, rarefying has been shown to be useful for very small (&lt;1000 reads/sample) or very uneven library sizes between groups (&gt;10x) (2), as well as important for community profiling (4). To perform rarefying, set the rare.opt to “rarewi” for rarefying with replacement to the minimum library depth and “rarewo” for rarefying without replacement to the minimum library depth. Use the <em>PlotRareCurve</em> to create a plot of rarefraction curves.</p>
<p><strong>Data scaling</strong></p>
<p>Scaling involves multiplying feature counts by a sample-specific factor to account for uneven sequence depth, transforming raw reads to relative abundances. The most commonly used method is Total sum scaling (TSS), whereby count data is divided by the total number of reads in a sample. This method has been criticized as the total number of reads can be dominated by a few most abundant features and bias resulting relative abundances (5). Moreover, TSS does for not account for heteroskedasticity of feature variance across measured values (2, 6). Other scaling factors such as the upper quantile (UQ) (7) and cumulative sum (CSS) (8) have been proposed that address such issues. Particularly, when performing differential abundance analysis, CSS has been recommended for controlling the false discovery rate (FDR) in data with large group sizes (&gt;10 samples) (9). However, when performing community-level comparisons such as estimating beta-diversity, TSS is recommended as it most accurately captures the composition of the original communities, whereas UQ and CSS distort communities (2, 3, 4).</p>
<p><strong>Data transformation</strong></p>
<p>The aim of data transformation is to stabilize the variance of the data. The centered log-ratio (10) is commonly used and is recommended due to the compositionality of microbiome data (11, 12). Furthermore, its variants, Relative log expression (RLE) and Trimmed mean of M-values (TMM)(13), have consistently demonstrated high performance at identifying differentially abundant features (3-5).</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true"></a><span class="co"># Option 1: No rarefying, total sum scaling and no transformation</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true"></a>mbSet&lt;-<span class="kw">PerformNormalization</span>(mbSet, <span class="dt">rare.opt=</span><span class="st">&quot;none&quot;</span>, <span class="dt">scale.opt=</span><span class="st">&quot;colsum&quot;</span>, <span class="dt">transform.opt=</span><span class="st">&quot;none&quot;</span>);</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true"></a><span class="co"># Option 2: Rarefying to the minimum library size + plotting the rarefraction curves</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true"></a>mbSet&lt;-<span class="kw">PerformNormalization</span>(mbSet, <span class="dt">rare.opt=</span><span class="st">&quot;rarewi&quot;</span>, <span class="dt">scale.opt=</span><span class="st">&quot;colsum&quot;</span>, <span class="dt">transform.opt=</span><span class="st">&quot;none&quot;</span>);</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true"></a>mbSet&lt;-<span class="kw">PlotRareCurve</span>(mbSet, <span class="dt">graphName=</span><span class="st">&quot;rarefraction_curve.png&quot;</span>, <span class="dt">variable=</span><span class="st">&quot;X&quot;</span>)</span></code></pre></div>
</div>
<div id="sweave-report-generation" class="section level2">
<h2>3. Sweave Report Generation</h2>
<p>Following analysis, a comprehensive report can be generated which contains a detailed description of each step performed in the R package, embedded with graphical and tabular outputs. To prepare the sweave report, please use the <em>CreatePDFReport</em> function. You must ensure that you have the nexessary LaTeX libraries to generate the report (i.e. texlive and texlive-fonts-extra). The object created <em>must</em> be named <em>mSet</em>, and specify the user name in quotation marks.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true"></a><span class="co"># Create Biomarker Sweave report </span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true"></a><span class="kw">PreparePDFReport</span>(mSet, <span class="st">&quot;User Name&quot;</span>)</span></code></pre></div>
</div>
<div id="references" class="section level2">
<h2>4.0 References</h2>
<ol style="list-style-type: decimal">
<li><p>Pereira MB, Wallroth M, Jonsson V, Kristiansson E. Comparison of normalization methods for the analysis of metagenomic gene abundance data. BMC Genomics. 2018;19(1):274.</p></li>
<li><p>Weiss S, Xu ZZ, Peddada S, Amir A, Bittinger K, Gonzalez A, et al. Normalization and microbial differential abundance strategies depend upon data characteristics. Microbiome. 2017;5(1):27.</p></li>
<li><p>McMurdie PJ, Holmes S. phyloseq: an R package for reproducible interactive analysis and graphics of microbiome census data. PLoS One. 2013;8(4):e61217.</p></li>
<li><p>McKnight DT, Huerlimann R, Bower DS, Schwarzkopf L, Alford RA, Zenger KR. Methods for normalizing microbiome data: An ecological perspective. Methods Ecol Evol. 2019;10(3):389-400.</p></li>
<li><p>Dillies MA, Rau A, Aubert J, Hennequet-Antier C, Jeanmougin M, Servant N, et al. A comprehensive evaluation of normalization methods for Illumina high-throughput RNA sequencing data analysis. Brief Bioinform. 2013;14(6):671-83.</p></li>
<li><p>Hugerth LW, Andersson AF. Analysing Microbial Community Composition through Amplicon Sequencing: From Sampling to Hypothesis Testing. Front Microbiol. 2017;8:1561.</p></li>
<li><p>Bullard JH, Purdom E, Hansen KD, Dudoit S. Evaluation of statistical methods for normalization and differential expression in mRNA-Seq experiments. BMC Bioinformatics. 2010;11(1):94.</p></li>
<li><p>Joseph N, Paulson C, Corrada Bravo H, Pop M. Robust methods for differential abundance analysis in marker gene surveys. Nat Methods. 2013;10:1200-2</p></li>
<li><p>Pereira MB, Wallroth M, Jonsson V, Kristiansson E. Comparison of normalization methods for the analysis of metagenomic gene abundance data. BMC Genomics. 2018;19(1):274.</p></li>
<li><p>Aitchison J. The Statistical-Analysis of Compositional Data. J Roy Stat Soc B Met. 1982;44(2):139-77.</p></li>
<li><p>Gloor GB, Macklaim JM, Pawlowsky-Glahn V, Egozcue JJ. Microbiome datasets are compositional: and this is not optional. Front Microbiol. 2017;8:2224.</p></li>
<li><p>Badri M, Kurtz Z, Muller C, Bonneau R. Normalization methods for microbial abundance data strongly affect correlation estimates. bioRxiv. 2018:406264.</p></li>
<li><p>Robinson MD, Oshlack A. A scaling normalization method for differential expression analysis of RNA-seq data. Genome Biol. 2010;11(3):R25.</p></li>
</ol>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
